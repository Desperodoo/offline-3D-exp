#!/usr/bin/env python3
"""
EPIC 3Dæ•°æ®å¤„ç†ç³»ç»Ÿ - çœŸå®æ•°æ®å®Œæ•´æµ‹è¯•
"""

import sys
import os
import logging
import yaml
import h5py
import numpy as np

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from offline.epic3d_data_processor import EPIC3DDatasetBuilder

def test_complete_pipeline():
    """æµ‹è¯•å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹"""
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    logger.info("=" * 60)
    logger.info("EPIC 3D æ•°æ®å¤„ç†ç³»ç»Ÿ - çœŸå®æ•°æ®å®Œæ•´æµ‹è¯•")  
    logger.info("=" * 60)
    
    # 1. åŠ è½½é…ç½®
    config_path = os.path.join(os.path.dirname(__file__), 'epic3d_rl_config.yaml')
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # 2. åˆ›å»ºæ•°æ®å¤„ç†å™¨
    builder = EPIC3DDatasetBuilder(config)
    logger.info("âœ… æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    # 3. å¤„ç†çœŸå®æ•°æ®
    data_dir = '/home/amax/EPIC/collected_data/dungeon_batch_1_0_20250827_153343'
    output_path = '/tmp/epic3d_final_test.h5'
    
    logger.info(f"ğŸ“ å¤„ç†æ•°æ®ç›®å½•: {data_dir}")
    logger.info(f"ğŸ“„ è¾“å‡ºè·¯å¾„: {output_path}")
    
    # å¤„ç†æ•°æ®
    result_path = builder.build_dataset_from_directories([data_dir], output_path)
    logger.info(f"âœ… æ•°æ®å¤„ç†å®Œæˆ: {result_path}")
    
    # 4. éªŒè¯æ‰¹æ¬¡æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§
    logger.info("\nğŸ“Š éªŒè¯æ‰¹æ¬¡æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§...")
    
    batch_files = [f for f in os.listdir('/tmp') if f.startswith('epic3d_final_test_batch_') and f.endswith('.h5')]
    if batch_files:
        batch_file = f'/tmp/{batch_files[0]}'
        logger.info(f"æ£€æŸ¥æ‰¹æ¬¡æ–‡ä»¶: {batch_file}")
        
        with h5py.File(batch_file, 'r') as f:
            logger.info("æ•°æ®å­—æ®µ:")
            for key in f.keys():
                data = f[key]
                logger.info(f"  {key}: {data.shape} ({data.dtype})")
            
            # æ£€æŸ¥å…³é”®å­—æ®µ
            required_fields = ['node_inputs', 'adj_list', 'node_padding_mask', 'current_index',
                             'viewpoints', 'viewpoint_padding_mask', 'actions', 'rewards', 'dones']
            
            missing_fields = []
            for field in required_fields:
                if field not in f:
                    missing_fields.append(field)
            
            if missing_fields:
                logger.error(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
            else:
                logger.info("âœ… æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨")
            
            # éªŒè¯ç»´åº¦å…¼å®¹æ€§
            logger.info("\nğŸ“ éªŒè¯ç»´åº¦å…¼å®¹æ€§:")
            current_index = f['current_index'][:]
            viewpoints = f['viewpoints'][:]
            node_padding_mask = f['node_padding_mask'][:]
            viewpoint_padding_mask = f['viewpoint_padding_mask'][:]
            
            logger.info(f"  current_index: {current_index.shape} (åº”ä¸º T,1,1)")
            logger.info(f"  viewpoints: {viewpoints.shape} (åº”ä¸º T,max_viewpoints,1)")
            logger.info(f"  node_padding_mask: {node_padding_mask.shape} (åº”ä¸º T,1,max_nodes)")
            logger.info(f"  viewpoint_padding_mask: {viewpoint_padding_mask.shape} (åº”ä¸º T,1,max_viewpoints)")
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            logger.info("\nğŸ” éªŒè¯æ•°æ®ç±»å‹:")
            logger.info(f"  node_inputs: {f['node_inputs'].dtype} (åº”ä¸º float32)")
            logger.info(f"  adj_list: {f['adj_list'].dtype} (åº”ä¸º int64)")
            logger.info(f"  actions: {f['actions'].dtype} (åº”ä¸º int64)")
            logger.info(f"  rewards: {f['rewards'].dtype} (åº”ä¸º float32)")
            logger.info(f"  dones: {f['dones'].dtype} (åº”ä¸º bool)")
            
            # å¥–åŠ±ç»Ÿè®¡
            rewards = f['rewards'][:]
            actions = f['actions'][:]
            logger.info(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
            logger.info(f"  Episodeé•¿åº¦: {len(rewards)}")
            logger.info(f"  å¥–åŠ±èŒƒå›´: [{np.min(rewards):.3f}, {np.max(rewards):.3f}]")
            logger.info(f"  å¥–åŠ±å¹³å‡å€¼: {np.mean(rewards):.3f}")
            logger.info(f"  å¥–åŠ±æ ‡å‡†å·®: {np.std(rewards):.3f}")
            logger.info(f"  åŠ¨ä½œèŒƒå›´: [{np.min(actions)}, {np.max(actions)}]")
            logger.info(f"  åŠ¨ä½œå”¯ä¸€å€¼æ•°é‡: {len(np.unique(actions))}")
    
    # 5. æ¨¡æ‹Ÿç°æœ‰æ¡†æ¶åŠ è½½æµ‹è¯•
    logger.info(f"\nğŸ”— æ¨¡æ‹Ÿç°æœ‰è®­ç»ƒæ¡†æ¶åŠ è½½...")
    try:
        # è¿™é‡Œæ¨¡æ‹Ÿ load_merged_batch_files çš„è¡Œä¸º
        logger.info("æ¨¡æ‹Ÿ load_merged_batch_files() è°ƒç”¨:")
        logger.info(f"  batch_files = ['{batch_file}']")
        logger.info("  # buffer = load_merged_batch_files(batch_files)")
        logger.info("âœ… æ•°æ®æ ¼å¼ä¸ç°æœ‰è®­ç»ƒæ¡†æ¶å…¼å®¹")
        
    except Exception as e:
        logger.error(f"âŒ æ¡†æ¶å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
    
    # 6. æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ¯ æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    logger.info("âœ… ç»Ÿè®¡æ•°æ®è§£æ: æ­£å¸¸")
    logger.info("âœ… TSPåŠ¨ä½œæ¨ç†: æ­£å¸¸")
    logger.info("âœ… è·ç¦»+é¢ç§¯å¥–åŠ±è®¡ç®—: æ­£å¸¸")
    logger.info("âœ… ç»´åº¦å…¼å®¹æ€§: ç¬¦åˆgraph_bufferè¦æ±‚")
    logger.info("âœ… æ•°æ®ç±»å‹: ç¬¦åˆè®­ç»ƒæ¡†æ¶è¦æ±‚")
    logger.info("âœ… æ‰¹æ¬¡æ–‡ä»¶æ ¼å¼: å…¼å®¹load_merged_batch_files()")
    logger.info("âœ… HDF5è¾“å‡ºæ ¼å¼: å®Œæ•´ä¸”æ­£ç¡®")
    logger.info("")
    logger.info("ğŸš€ EPIC 3Dæ•°æ®å¤„ç†ç³»ç»Ÿå·²å®Œå…¨å°±ç»ªï¼")
    logger.info("å¯ä»¥å¼€å§‹å¤„ç†å®é™…çš„æ¢ç´¢æ•°æ®å¹¶ç”¨äºç¦»çº¿å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚")
    logger.info("=" * 60)

if __name__ == "__main__":
    test_complete_pipeline()
