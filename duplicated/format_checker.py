#!/usr/bin/env python3
"""
æ•°æ®æ ¼å¼æ£€æŸ¥å™¨ - æ£€æŸ¥EPIC 3Dæ•°æ®å¤„ç†ç”Ÿæˆçš„æ•°æ®ä¸graph_bufferæœŸæœ›æ ¼å¼çš„å…¼å®¹æ€§
"""

import numpy as np
import h5py
from pathlib import Path
import yaml
from collections import namedtuple

# ä»graph_buffer.pyä¸­å¯¼å…¥çš„æ•°æ®ç»“æ„å®šä¹‰
GraphTimeStep = namedtuple('GraphTimeStep', 
                          ['node_inputs', 'node_padding_mask', 'current_index',
                           'viewpoints', 'viewpoint_padding_mask', 'adj_list',
                           'action', 'logp', 'reward', 'done', 'first'])

def load_config(config_path):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def check_epic3d_format(data_file):
    """æ£€æŸ¥EPIC 3Dæ•°æ®æ–‡ä»¶æ ¼å¼"""
    print(f"=== æ£€æŸ¥EPIC 3Dæ•°æ®æ–‡ä»¶: {data_file} ===")
    
    if not Path(data_file).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return False
    
    try:
        with h5py.File(data_file, 'r') as f:
            print("ğŸ“Š æ•°æ®é›†å­—æ®µ:")
            for key in f.keys():
                dataset = f[key]
                if isinstance(dataset, h5py.Dataset):
                    print(f"  {key}: {dataset.shape} ({dataset.dtype})")
                else:
                    print(f"  {key}: {type(dataset)}")
            
            print("\nğŸ“‹ å…ƒæ•°æ®å±æ€§:")
            for key in f.attrs.keys():
                print(f"  {key}: {f.attrs[key]}")
            
            # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
            required_fields = [
                'node_inputs', 'node_padding_mask', 'current_index',
                'viewpoints', 'viewpoint_padding_mask', 'adj_list',
                'actions', 'rewards', 'dones'
            ]
            
            missing_fields = []
            for field in required_fields:
                if field not in f.keys():
                    missing_fields.append(field)
            
            if missing_fields:
                print(f"\nâŒ ç¼ºå¤±å¿…è¦å­—æ®µ: {missing_fields}")
                return False
            else:
                print(f"\nâœ… æ‰€æœ‰å¿…è¦å­—æ®µéƒ½å­˜åœ¨")
            
            # æ£€æŸ¥æ•°æ®ç»´åº¦ä¸€è‡´æ€§
            sample_count = len(f['actions'])
            print(f"\nğŸ“ æ•°æ®ç»´åº¦æ£€æŸ¥ (æ ·æœ¬æ•°: {sample_count}):")
            
            for field in required_fields:
                if field in f.keys():
                    expected_first_dim = sample_count
                    actual_first_dim = f[field].shape[0]
                    if expected_first_dim == actual_first_dim:
                        print(f"  âœ… {field}: {f[field].shape}")
                    else:
                        print(f"  âŒ {field}: {f[field].shape} (æœŸæœ›ç¬¬ä¸€ç»´åº¦: {expected_first_dim})")
                        return False
            
            # æ£€æŸ¥å…·ä½“çš„æ•°æ®æ ¼å¼è¦æ±‚
            print(f"\nğŸ” æ ¼å¼è¯¦ç»†æ£€æŸ¥:")
            
            # æ£€æŸ¥node_padding_maskæ˜¯å¦ä¸ºå¸ƒå°”ç±»å‹
            if f['node_padding_mask'].dtype != bool:
                print(f"  âš ï¸  node_padding_maskåº”ä¸ºboolç±»å‹ï¼Œå½“å‰ä¸º: {f['node_padding_mask'].dtype}")
            else:
                print(f"  âœ… node_padding_maskç±»å‹æ­£ç¡®: {f['node_padding_mask'].dtype}")
            
            # æ£€æŸ¥viewpoint_padding_maskæ˜¯å¦ä¸ºå¸ƒå°”ç±»å‹  
            if f['viewpoint_padding_mask'].dtype != bool:
                print(f"  âš ï¸  viewpoint_padding_maskåº”ä¸ºboolç±»å‹ï¼Œå½“å‰ä¸º: {f['viewpoint_padding_mask'].dtype}")
            else:
                print(f"  âœ… viewpoint_padding_maskç±»å‹æ­£ç¡®: {f['viewpoint_padding_mask'].dtype}")
            
            # æ£€æŸ¥donesæ˜¯å¦ä¸ºå¸ƒå°”ç±»å‹
            if f['dones'].dtype != bool:
                print(f"  âš ï¸  donesåº”ä¸ºboolç±»å‹ï¼Œå½“å‰ä¸º: {f['dones'].dtype}")
            else:
                print(f"  âœ… donesç±»å‹æ­£ç¡®: {f['dones'].dtype}")
            
            # æ£€æŸ¥actionsæ˜¯å¦ä¸ºæ•´æ•°ç±»å‹
            if not np.issubdtype(f['actions'].dtype, np.integer):
                print(f"  âŒ actionsåº”ä¸ºæ•´æ•°ç±»å‹ï¼Œå½“å‰ä¸º: {f['actions'].dtype}")
                return False
            else:
                print(f"  âœ… actionsç±»å‹æ­£ç¡®: {f['actions'].dtype}")
            
            # æ£€æŸ¥rewardsæ˜¯å¦ä¸ºæµ®ç‚¹ç±»å‹
            if not np.issubdtype(f['rewards'].dtype, np.floating):
                print(f"  âŒ rewardsåº”ä¸ºæµ®ç‚¹ç±»å‹ï¼Œå½“å‰ä¸º: {f['rewards'].dtype}")
                return False
            else:
                print(f"  âœ… rewardsç±»å‹æ­£ç¡®: {f['rewards'].dtype}")
            
            print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
            print(f"  åŠ¨ä½œèŒƒå›´: {f['actions'][:].min()} - {f['actions'][:].max()}")
            print(f"  å¥–åŠ±èŒƒå›´: {f['rewards'][:].min():.3f} - {f['rewards'][:].max():.3f}")
            print(f"  å¥–åŠ±å‡å€¼: {f['rewards'][:].mean():.3f}")
            print(f"  å®Œæˆæ ‡å¿—æ•°é‡: {f['dones'][:].sum()}")
            
            return True
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def check_graph_buffer_compatibility():
    """æ£€æŸ¥ä¸graph_bufferçš„å…¼å®¹æ€§"""
    print(f"\n=== æ£€æŸ¥ä¸GraphReplayBufferçš„å…¼å®¹æ€§ ===")
    
    # ä»graph_buffer.pyæ£€æŸ¥æœŸæœ›çš„æ•°æ®æ ¼å¼
    print("ğŸ“‹ GraphTimeStepæœŸæœ›çš„å­—æ®µ:")
    for field in GraphTimeStep._fields:
        print(f"  - {field}")
    
    print("\nğŸ”„ å­—æ®µæ˜ å°„å…³ç³»:")
    mapping = {
        'node_inputs': 'node_inputs âœ…',
        'node_padding_mask': 'node_padding_mask âœ…', 
        'current_index': 'current_index âœ…',
        'viewpoints': 'viewpoints âœ…',
        'viewpoint_padding_mask': 'viewpoint_padding_mask âœ…',
        'adj_list': 'adj_list âœ…',
        'action': 'actions âœ… (å¤æ•°å½¢å¼)',
        'logp': 'âŒ ç¼ºå¤± (æ—¥å¿—æ¦‚ç‡)',
        'reward': 'rewards âœ… (å¤æ•°å½¢å¼)',
        'done': 'dones âœ… (å¤æ•°å½¢å¼)', 
        'first': 'âŒ ç¼ºå¤± (é¦–ä¸ªæ—¶é—´æ­¥æ ‡å¿—)'
    }
    
    for graph_field, epic_field in mapping.items():
        print(f"  {graph_field} -> {epic_field}")
    
    print(f"\nâš ï¸  æ³¨æ„äº‹é¡¹:")
    print(f"  1. logpå­—æ®µç¼ºå¤± - è¿™å¯¹ç¦»çº¿RLè®­ç»ƒå¯èƒ½ä¸æ˜¯é—®é¢˜")
    print(f"  2. firstå­—æ®µç¼ºå¤± - å¯èƒ½éœ€è¦ä»episodeè¾¹ç•Œæ¨å¯¼")
    print(f"  3. å­—æ®µåç§°ç•¥æœ‰å·®å¼‚ï¼ˆå•æ•°vså¤æ•°ï¼‰")

def check_topo_data_format(topo_file):
    """æ£€æŸ¥åŸå§‹topoæ•°æ®æ ¼å¼"""
    print(f"\n=== æ£€æŸ¥åŸå§‹Topoæ•°æ®æ ¼å¼: {topo_file} ===")
    
    if not Path(topo_file).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {topo_file}")
        return False
    
    try:
        with open(topo_file, 'r') as f:
            lines = f.readlines()
        
        print(f"ğŸ“„ æ–‡ä»¶ä¿¡æ¯: {len(lines)} è¡Œ")
        
        # æŸ¥æ‰¾å…³é”®éƒ¨åˆ†
        sections_found = {}
        node_count = 0
        edge_count = 0
        viewpoint_count = 0
        current_position_count = 0
        tsp_section = False
        viewpoint_section = False
        
        for i, line in enumerate(lines[:100]):  # åªæ£€æŸ¥å‰100è¡Œ
            line = line.strip()
            if "EXPLORATION STATISTICS" in line:
                sections_found['stats'] = i
            elif line == "NODES":
                sections_found['nodes'] = i
            elif line == "EDGES":
                sections_found['edges'] = i
            elif line == "TSP_ORDER":
                sections_found['tsp'] = i
                tsp_section = True
            elif line == "VIEWPOINTS":
                sections_found['viewpoints'] = i
                viewpoint_section = True
            elif "is_viewpoint" in line and not line.startswith("#"):
                # è§£æèŠ‚ç‚¹è¡Œ
                parts = line.split()
                if len(parts) >= 6:
                    is_viewpoint = bool(int(parts[5]))
                    is_current = bool(int(parts[6])) if len(parts) > 6 else False
                    tsp_order = int(parts[10]) if len(parts) > 10 else -1
                    
                    if is_viewpoint:
                        viewpoint_count += 1
                    if is_current:
                        current_position_count += 1
                    node_count += 1
        
        print(f"ğŸ“Š å‘ç°çš„æ•°æ®æ®µ:")
        for section, line_num in sections_found.items():
            print(f"  {section}: ç¬¬{line_num}è¡Œ")
        
        print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡ (å‰100è¡Œè§£æ):")
        print(f"  èŠ‚ç‚¹æ•°: {node_count}")
        print(f"  è§†ç‚¹æ•°: {viewpoint_count}")
        print(f"  å½“å‰ä½ç½®æ•°: {current_position_count}")
        print(f"  åŒ…å«TSPæ®µ: {tsp_section}")
        print(f"  åŒ…å«VIEWPOINTæ®µ: {viewpoint_section}")
        
        # æ£€æŸ¥èŠ‚ç‚¹æ ¼å¼æ˜¯å¦æ­£ç¡®
        expected_node_fields = [
            'node_id', 'x', 'y', 'z', 'yaw', 'is_viewpoint', 'is_current', 
            'is_history', 'region_id', 'is_reachable', 'tsp_order_index', 
            'distance', 'observation_score', 'cluster_distance'
        ]
        
        print(f"\nğŸ“‹ æœŸæœ›çš„èŠ‚ç‚¹å­—æ®µ ({len(expected_node_fields)}ä¸ª):")
        for field in expected_node_fields:
            print(f"  - {field}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥topoæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” EPIC 3D æ•°æ®æ ¼å¼æ£€æŸ¥å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = "epic3d_rl_config.yaml"
    if Path(config_path).exists():
        print(f"âœ… æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_path}")
        config = load_config(config_path)
        print(f"ğŸ“‹ é…ç½®å‚æ•°: {config}")
    else:
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¤ºä¾‹æ•°æ®æ–‡ä»¶
    example_topo = "/home/amax/EPIC/collected_data/forest_batch_4_3_20250826_161355/filtered_data/topo_graph_1756196044.598018.txt"
    if Path(example_topo).exists():
        check_topo_data_format(example_topo)
    else:
        print(f"âš ï¸  ç¤ºä¾‹topoæ–‡ä»¶ä¸å­˜åœ¨: {example_topo}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„HDF5æ•°æ®æ–‡ä»¶
    example_hdf5 = "epic3d_dataset.h5"
    if Path(example_hdf5).exists():
        check_epic3d_format(example_hdf5)
    else:
        print(f"âš ï¸  ç¤ºä¾‹HDF5æ–‡ä»¶ä¸å­˜åœ¨: {example_hdf5}")
    
    # æ£€æŸ¥å…¼å®¹æ€§
    check_graph_buffer_compatibility()
    
    print(f"\n" + "=" * 50)
    print("ğŸ æ£€æŸ¥å®Œæˆ")

if __name__ == "__main__":
    main()
