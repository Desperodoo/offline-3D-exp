#!/usr/bin/env python3
"""
EPIC 3Dæ•°æ®å¤„ç†çœŸå®æ•°æ®æµ‹è¯•

ä½¿ç”¨çœŸå®çš„dungeon explorationæ•°æ®æµ‹è¯•EPIC3Dæ•°æ®å¤„ç†ç³»ç»Ÿ
"""

import os
import sys
import yaml
import logging
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from offline.epic3d_data_processor import EPIC3DDatasetBuilder

def setup_logging():
    """è®¾ç½®è¯¦ç»†æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def test_real_data_processing():
    """æµ‹è¯•çœŸå®æ•°æ®å¤„ç†"""
    logger = setup_logging()
    logger.info("å¼€å§‹çœŸå®æ•°æ®å¤„ç†æµ‹è¯•...")
    
    # 1. åŠ è½½é…ç½®
    config_path = os.path.join(os.path.dirname(__file__), 'epic3d_rl_config.yaml')
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    logger.info(f"âœ“ é…ç½®åŠ è½½å®Œæˆ")
    
    # 2. è®¾ç½®æµ‹è¯•æ•°æ®è·¯å¾„
    data_dir = "/home/amax/EPIC/collected_data/dungeon_batch_1_0_20250827_153343"
    output_dir = "/home/amax/EPIC/src/offline/test_outputs"
    os.makedirs(output_dir, exist_ok=True)
    
    logger.info(f"æµ‹è¯•æ•°æ®ç›®å½•: {data_dir}")
    logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # 3. éªŒè¯æ•°æ®ç›®å½•å­˜åœ¨
    if not os.path.exists(data_dir):
        logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
        
    filtered_data_dir = os.path.join(data_dir, 'filtered_data')
    if not os.path.exists(filtered_data_dir):
        logger.error(f"filtered_dataç›®å½•ä¸å­˜åœ¨: {filtered_data_dir}")
        return False
    
    # æ£€æŸ¥topo_graphæ–‡ä»¶æ•°é‡
    import glob
    topo_files = glob.glob(os.path.join(filtered_data_dir, 'topo_graph_*.txt'))
    logger.info(f"æ‰¾åˆ° {len(topo_files)} ä¸ªtopo_graphæ–‡ä»¶")
    
    if len(topo_files) == 0:
        logger.error("æœªæ‰¾åˆ°topo_graphæ–‡ä»¶")
        return False
    
    # 4. åˆ›å»ºæ•°æ®å¤„ç†å™¨
    builder = EPIC3DDatasetBuilder(config)
    logger.info("âœ“ æ•°æ®å¤„ç†å™¨åˆ›å»ºæˆåŠŸ")
    
    # 5. å¤„ç†æ•°æ®
    try:
        start_time = time.time()
        
        # å•ä¸ªepisodeæµ‹è¯•
        logger.info(f"å¼€å§‹å¤„ç†episode: {data_dir}")
        output_path = os.path.join(output_dir, "dungeon_test_episode.h5")
        
        # è°ƒç”¨å¤„ç†æ–¹æ³•
        result_path = builder.build_dataset_from_directories([data_dir], output_path)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        logger.info(f"âœ“ æ•°æ®å¤„ç†å®Œæˆï¼")
        logger.info(f"å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        logger.info(f"è¾“å‡ºæ–‡ä»¶: {result_path}")
        
        # 6. éªŒè¯è¾“å‡ºæ–‡ä»¶
        if os.path.exists(result_path):
            file_size = os.path.getsize(result_path) / (1024 * 1024)  # MB
            logger.info(f"âœ“ è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆï¼Œå¤§å°: {file_size:.2f}MB")
            
            # æ£€æŸ¥æ‰¹æ¬¡æ–‡ä»¶
            base_path = result_path.replace('.h5', '')
            batch_files = glob.glob(f"{base_path}_batch_*.h5")
            logger.info(f"âœ“ ç”Ÿæˆäº† {len(batch_files)} ä¸ªæ‰¹æ¬¡æ–‡ä»¶")
            for batch_file in batch_files:
                batch_size = os.path.getsize(batch_file) / (1024 * 1024)
                logger.info(f"  - {os.path.basename(batch_file)}: {batch_size:.2f}MB")
                
        else:
            logger.error("âœ— è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ")
            return False
            
        # 7. éªŒè¯HDF5æ–‡ä»¶å†…å®¹
        try:
            import h5py
            logger.info("éªŒè¯HDF5æ–‡ä»¶å†…å®¹...")
            
            with h5py.File(result_path, 'r') as f:
                logger.info("ä¸»è¦æ•°æ®é›†:")
                for key in f.keys():
                    if isinstance(f[key], h5py.Dataset):
                        logger.info(f"  - {key}: {f[key].shape} ({f[key].dtype})")
                
                logger.info("æ–‡ä»¶å±æ€§:")
                for attr_name in f.attrs:
                    logger.info(f"  - {attr_name}: {f.attrs[attr_name]}")
            
            # éªŒè¯æ‰¹æ¬¡æ–‡ä»¶
            if batch_files:
                batch_file = batch_files[0]
                logger.info(f"éªŒè¯æ‰¹æ¬¡æ–‡ä»¶: {os.path.basename(batch_file)}")
                with h5py.File(batch_file, 'r') as f:
                    logger.info("æ‰¹æ¬¡æ–‡ä»¶æ•°æ®é›†:")
                    for key in f.keys():
                        if isinstance(f[key], h5py.Dataset):
                            logger.info(f"  - {key}: {f[key].shape} ({f[key].dtype})")
                    
                    logger.info("æ‰¹æ¬¡æ–‡ä»¶å±æ€§:")
                    for attr_name in f.attrs:
                        logger.info(f"  - {attr_name}: {f.attrs[attr_name]}")
                        
        except Exception as e:
            logger.error(f"éªŒè¯HDF5æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False
        
        logger.info("âœ… çœŸå®æ•°æ®å¤„ç†æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âœ— æ•°æ®å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_multiple_episodes():
    """æµ‹è¯•å¤šä¸ªepisodeå¤„ç†"""
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹å¤šepisodeå¤„ç†æµ‹è¯•...")
    
    # é€‰æ‹©å‡ ä¸ªdungeon episodeè¿›è¡Œæµ‹è¯•
    collected_data_dir = "/home/amax/EPIC/collected_data"
    import glob
    
    dungeon_episodes = glob.glob(os.path.join(collected_data_dir, "dungeon_batch_*"))
    dungeon_episodes.sort()
    
    # é€‰æ‹©å‰3ä¸ªepisodeè¿›è¡Œæµ‹è¯•
    test_episodes = dungeon_episodes[:3]
    logger.info(f"é€‰æ‹© {len(test_episodes)} ä¸ªepisodeè¿›è¡Œæµ‹è¯•:")
    for ep in test_episodes:
        logger.info(f"  - {os.path.basename(ep)}")
    
    # åŠ è½½é…ç½®
    config_path = os.path.join(os.path.dirname(__file__), 'epic3d_rl_config.yaml')
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºå¤„ç†å™¨
    builder = EPIC3DDatasetBuilder(config)
    
    # è¾“å‡ºè·¯å¾„
    output_dir = "/home/amax/EPIC/src/offline/test_outputs"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "dungeon_multi_episodes.h5")
    
    try:
        start_time = time.time()
        result_path = builder.build_dataset_from_directories(test_episodes, output_path)
        end_time = time.time()
        
        logger.info(f"âœ“ å¤šepisodeå¤„ç†å®Œæˆï¼")
        logger.info(f"å¤„ç†æ—¶é—´: {end_time - start_time:.2f}ç§’")
        logger.info(f"è¾“å‡ºæ–‡ä»¶: {result_path}")
        
        # éªŒè¯è¾“å‡º
        import h5py
        with h5py.File(result_path, 'r') as f:
            logger.info(f"æ€»episodes: {f.attrs.get('num_episodes', 'unknown')}")
            logger.info(f"æ€»æ ·æœ¬æ•°: {f.attrs.get('total_samples', 'unknown')}")
            
            if 'actions' in f:
                logger.info(f"Actions shape: {f['actions'].shape}")
            if 'rewards' in f:
                logger.info(f"Rewards shape: {f['rewards'].shape}")
        
        return True
        
    except Exception as e:
        logger.error(f"å¤šepisodeå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=" * 60)
    print("EPIC 3D çœŸå®æ•°æ®å¤„ç†æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•å•ä¸ªepisode
    print("\n1. æµ‹è¯•å•ä¸ªepisodeå¤„ç†...")
    success1 = test_real_data_processing()
    
    if success1:
        print("\n2. æµ‹è¯•å¤šä¸ªepisodeå¤„ç†...")
        success2 = test_multiple_episodes()
    else:
        success2 = False
    
    print("\n" + "=" * 60)
    if success1 and success2:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼çœŸå®æ•°æ®å¤„ç†ç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
    elif success1:
        print("âš ï¸  å•episodeæµ‹è¯•é€šè¿‡ï¼Œå¤šepisodeæµ‹è¯•å¤±è´¥ã€‚")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥æ•°æ®å¤„ç†é€»è¾‘ã€‚")
    print("=" * 60)
